{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WPylkxI7S73"
   },
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TAnIgoXgv3FI"
   },
   "outputs": [],
   "source": [
    "# Update packages and install required java version\n",
    "!apt-get update\n",
    "!apt-get install openjdk-21-jdk-headless -qq > /dev/null\n",
    "\n",
    "# download and unzip spark\n",
    "!wget -nc -q https://downloads.apache.org/spark/spark-4.0.0/spark-4.0.0-bin-hadoop3.tgz\n",
    "!tar xf spark-4.0.0-bin-hadoop3.tgz\n",
    "\n",
    "# get data for labs\n",
    "!wget -nc -O around_the_world_in_80_days.txt https://www.gutenberg.org/ebooks/103.txt.utf-8\n",
    "\n",
    "# install findspark\n",
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "amepofAo0Z88"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark\n",
    "\n",
    "# set env vars for java and spark\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-21-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-4.0.0-bin-hadoop3\"\n",
    "\n",
    "# start findspark so notebook can interact with spark\n",
    "findspark.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zmv2ros75Gnu"
   },
   "outputs": [],
   "source": [
    "# what does findspark do? use the ?? magic command to find out\n",
    "# Note 1: in colab, this may open in a side panel\n",
    "# Note 2: this magic command is often helpful when encountering an object in a\n",
    "# notebook that is unfamiliar. More information will be displayed if it exists\n",
    "?? findspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyrzgODB7h-I"
   },
   "source": [
    "# 1. Word Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubaJBAcmHN7w"
   },
   "source": [
    "Instructions:  \n",
    "For each cell marked \"double-click and add explanation here\" please answer the question in your own words.  \n",
    "In the section where you complete the code to perform basic nlp text cleaning and exploration tasks, the goal is to chain all of the transformations together in a single function. For learning and exploration purposes, it is acceptable to have each step seperate, but the last cell in this section should be one function with all transformations chained together.  \n",
    "For steps c and f, it is acceptable to use your favorite chatbot to generate a list of common stop words (c) and punctuation (e) for use in the code. As these are common steps in nlp/text processing tasks, there are pleanty of libraries to help with this such as nltk, but there is no need to import extra dependencies for this lab unless you are already familiar with working with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sT9v8V8z3xRh"
   },
   "outputs": [],
   "source": [
    "# start a spark session and create spark context for making rdd\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"word_count\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQuzr4jFgwA8"
   },
   "outputs": [],
   "source": [
    "# Defind the rdd\n",
    "rdd = sc.textFile('/content/around_the_world_in_80_days.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDOA5KkhhEpe"
   },
   "outputs": [],
   "source": [
    "# view the first x lines of the rdd\n",
    "rdd.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Ygmzp9YhIuc"
   },
   "outputs": [],
   "source": [
    "# example lambda function\n",
    "words = rdd.flatMap(lambda lines: lines.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cx0OTFbfhTmg"
   },
   "outputs": [],
   "source": [
    "# Note and explain the output of the below command\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ebu8bJo8yTa"
   },
   "source": [
    "double-click and add explanation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSFM2oMV8a4l"
   },
   "source": [
    "<ADD EXPLANATIONâ€¯HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mZ0xArEv8u_0"
   },
   "outputs": [],
   "source": [
    "# Note and explain the output of the following command, focusing on the difference with the\n",
    "# above command\n",
    "words.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8xJlKEB9aDY"
   },
   "source": [
    "double-click and add explanation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eD96cn2NhUaZ"
   },
   "outputs": [],
   "source": [
    "# nicer print\n",
    "for w in words.collect():\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tQ4EUF7hyDx"
   },
   "outputs": [],
   "source": [
    "# Print first x words\n",
    "words.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6M0MIGmEVrq"
   },
   "outputs": [],
   "source": [
    "# Use cell magic command to help understand what the rdd.flatMap function is doing in the next cell.\n",
    "# Insert a text/markdown cell and explain in your own words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BdkOE8Pzh4sV"
   },
   "outputs": [],
   "source": [
    "# Initialize a word counter by creating a tuple with word and cound of 1\n",
    "words = rdd.flatMap(lambda lines: lines.split(' ')) \\\n",
    "                    .map(lambda word: (word, 1))\n",
    "\n",
    "for w in words.collect():\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFu72I93_8CS"
   },
   "outputs": [],
   "source": [
    "# a. count the occurence of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dYAIt8A8AGGn"
   },
   "outputs": [],
   "source": [
    "# b. a common first step in text analysis, change all capital letters to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CNr23N3MAVla"
   },
   "outputs": [],
   "source": [
    "# c. eliminate the stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HjOm9cn7B5lI"
   },
   "outputs": [],
   "source": [
    "# d. sort in alphabetical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WXrqvUwuCD5E"
   },
   "outputs": [],
   "source": [
    "# e. sort descending by word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AJr1n25lCN2B"
   },
   "outputs": [],
   "source": [
    "# f. remove punctuations and blank spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81MYw5zXCv8X"
   },
   "source": [
    "# 2. What does the following cell block do?\n",
    "Comment the code below line by line after the provided hash-tag. You should be able to explain each line while respecting the pep8 style guide of 79 characters or less per line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FrrNF7seCaZ2"
   },
   "outputs": [],
   "source": [
    " # Create an RDD of tuples (name, age)\n",
    "dataRDD = sc.parallelize([(\"Brooke\", 20), (\"Denny\", 31), (\"Jules\", 30),\n",
    "(\"TD\", 35), (\"Brooke\", 25)])\n",
    "\n",
    "# Try to undestand what this code does (line by line)\n",
    "agesRDD = (dataRDD\n",
    "  #\n",
    "  .map(lambda x: (x[0], (x[1], 1)))\n",
    "  #\n",
    "  .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "  #\n",
    "  .map(lambda x: (x[0], x[1][0]/x[1][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rzas64DSRt_a"
   },
   "source": [
    "# Where to go from here\n",
    "\n",
    "Further exploration for students who complete the lab before the end of the session or want to go further.\n",
    "\n",
    "- perform eda on the original french version of the [book](https://www.gutenberg.org/ebooks/46541.txt.utf-8) and compare the two\n",
    "- recomplete the exercises using a the docker install\n",
    "- install java and spark directly onto host machine and either rexplore this notebook or perform eda on other data sets\n",
    "- write a simple python timer function for seeing how quickly your rdd runs as written. change the order of the steps in order to make the rdd run as optimally as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XH329uSEU0s_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
