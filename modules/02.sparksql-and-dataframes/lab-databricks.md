# Data Engineering with Spark

## Lab 2: Structured data analysis with DataFrames and SparkSQL

Analyze DataFrames with SparkSQL

### Prerequisites

- Connect to the [Databricks Free Edition](https://community.cloud.databricks.com/login.html)
- Upload the provided notebook

### Goals

- Get familiar with the most frequently used functions for dataframe processing such as `filter`, `select`, `groupby`, etc...
- Learn when and how to use the functions from the module `pyspark.sql.functions
- Learn how to enrich the data through `joins`

### Lab resources

- Notebook
- The datasets will be loaded into Databricks from [nyc.gov TLC Trip Record Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)

### Useful links

- [PySpark Documentation](https://spark.apache.org/docs/latest/api/python/index.html)
- [Pyspark SQL Module doc](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html)

### TO DO

Go through the notebook and explore the dataset using the questions provided. By the end of the lab you should have gained a better understanding of commuting by taxi in nyc.
